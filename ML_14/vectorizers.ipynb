{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJnHQn4htNIF",
    "outputId": "a9944aca-2fa0-4a26-f0ce-1b32ccd9705a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.15.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (2.24.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (1.19.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (2021.11.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (3.7.4.post0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (21.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (0.1.2)\n",
      "Requirement already satisfied: dill in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (6.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (1.1.3)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\admin\\anaconda3\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (5.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing<3,>=2.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.4)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.6.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (5.1.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (20.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pandas->datasets) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: tokenizers==0.10.0rc1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.10.0rc1)\n",
      "Requirement already satisfied: wandb in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.12.6)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (2.24.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (5.1.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (3.1.24)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (5.7.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (1.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (2.8.1)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: promise<3,>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (5.3.1)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: pathtools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (1.15.0)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from GitPython>=1.0.0->wandb) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install tokenizers==0.10.0rc1\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IGJsIqgRtEn-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import datasets\n",
    "import tokenizers\n",
    "import wandb\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYu-_i_CeThC"
   },
   "source": [
    "## О формате заданий\n",
    "\n",
    "### Coding tasks\n",
    "\n",
    "\n",
    "Место для вашего кода отмечено блоками `# YOUR CODE STARTS` ... `#YOUR CODE ENDS` и ваше решение должно быть строго между ними. \n",
    "\n",
    "Чтобы решить задачу, вам придётся смотреть в документацию соответствующего фреймворка. Этот навык очень важен, и в начале мы будем намекать вам на название метода, который вам нужно использовать. Такой подход позволит плавно приблизить вас к более реалистичным задачам.\n",
    "\n",
    "\n",
    "\n",
    "![image.png](https://files.realpython.com/media/Practical-Text-Classification-with-Keras-and-Python_Watermark.fe326bd75146.jpg)\n",
    "\n",
    "Image source: [тык](https://realpython.com/python-keras-text-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "LUvFcan-tG5e",
    "outputId": "3ab48820-0022-496a-ee5d-48f313eae75b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (C:\\Users\\admin\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\e3c66f1788a67a89c7058d97ff62b6c30531e05b549de56d3ab91891f0561f9a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1defcd7ed0c4856945ab69d5ffee671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_dataset = datasets.load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JrixvHI6teb"
   },
   "source": [
    "**IMDB** - это датасет по классификации эмоциональной окраски. Вам нужно предсказать положительный ли отзыв к фильму по его тексту. Это довольно простая задача и она хорошо решается даже линейными моделями. Для доступа к нему мы используем библиотеку `datasets` - она содержит в себе много интересных текстовых датасетов.\n",
    "\n",
    "Тренировочная и тстовая части IMDB достаточно большие - каждая состоит из 25 тысяч примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GL4eJ8hcwHA_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUVSXa2r7oak"
   },
   "source": [
    "Как мы видим, классы сбалансированны, что позволяет использовать accuracy как простую и интерпретируемую метрику, хорошо показывающую качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wbCkXd6_7VU_"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels = [e['label'] for e in text_dataset['train']]\n",
    "plt.hist(train_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "o04VWlLvwpDd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SdqU7ZTiwrC9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_dataset['train']['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVemry0mziTa"
   },
   "source": [
    "# Classification using a linear model\n",
    "\n",
    "Линейная модель - очень сильный бейзлайн и в некоторых задачах классификации вам даже не надо идти дальше линейной модели - она уже достаточно хороша. А также её можно написать менее чем в 10 строчекю Поэтому всегда стоит начинать решение любой задачи с ленейного бейзлайна.\n",
    "\n",
    "Давайте вспомним библиотеку `sklearn` и напишем линейную модельку. Для векторизации текста мы будем использовать `TfidfVectorizer`, а в качестве модели `LogisticRegression`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fMU_c9pKxe0d"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "i5qXrSEXztwW"
   },
   "outputs": [],
   "source": [
    "# TASK 1.1: create TfidfVectorizer object and fit it on out training set texts\n",
    "# Our implementation is 2 lines\n",
    "# YOUR CODE STARTS\n",
    "vectorizer = TfidfVectorizer()\n",
    "values = vectorizer.fit(text_dataset['train']['text'])\n",
    "# YOUR CODE ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RRkJP8yz2KPP"
   },
   "outputs": [],
   "source": [
    "# TASK 1.2:\n",
    "# 1. convert your texts to tf-idf vectors using .transform (training texts and test texts too)\n",
    "# 2. convert your labels into numpy arrays (both training and test labels)\n",
    "# Or implementatin is 4 lines\n",
    "\n",
    "# YOUR CODE STARTS\n",
    "X_train = vectorizer.transform(text_dataset['train']['text'])\n",
    "y_train = np.array(text_dataset['train']['label'])\n",
    "\n",
    "X_test = vectorizer.transform(text_dataset['test']['text'])\n",
    "y_test = np.array(text_dataset['test']['label'])\n",
    "# YOUR CODE ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_FAAuos63UtS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<25000x74849 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 3445861 stored elements in Compressed Sparse Row format>,\n",
       " array([1, 1, 1, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gnWo2pLB1ho0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK 1.3: create LogisticRegression model object and fit the model\n",
    "# Our implementation is 2 lines\n",
    "# YOUR CODE STARTS\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# YOUR CODE ENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJRuIbVrqDpR"
   },
   "source": [
    "А теперь мы используем нашу модель для того, чтобы предсказать классы на тестовом сете и считаем accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZKCOA3SE3kSK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(type(predictions))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "pyO4CMzB3jds"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88316"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that we can use vector operations, because we deal with numpy tensors\n",
    "accuracy = (predictions == y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AENaKt7huHd1"
   },
   "source": [
    "**OMG so accurate, much machine learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NpZecL4qqI5"
   },
   "source": [
    "Давайте предскажем позитивны ли такие комментарии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XKlLVQUqsRlI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_comment = 'This movie is awesome!'\n",
    "\n",
    "vec = vectorizer.transform([positive_comment])\n",
    "model.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CHtq-453t2Gb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_comment = 'This movie is awful!'\n",
    "\n",
    "vec = vectorizer.transform([negative_comment])\n",
    "model.predict(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xm2GycUTTjgW"
   },
   "source": [
    "Как мы увидели, даже такая простая модель может хорошо классифицировать текст (accuracy 0.9 - это довольно много, тк выборка сбалансированна).\n",
    "\n",
    "Кстати, использование модели LinearSVM обычно работает даже лучше, чем логистическая регрессия. Рекомендуем попробовать и сравнить.\n",
    "\n",
    "Что такое SVM: [тык](https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47)\n",
    "\n",
    "Ещё один простой метод улучшить линейную модель - использовать n-gram в вашем TF-IDF. Не забудьте указать параметр `max_features` (хорошое число 50 000), а то при большом количестве фичей модель может начать переобучаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используем LinearSVM, n-gram, LemmaTokenizer ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "# TASK 1.1: create TfidfVectorizer object and fit it on out training set texts\n",
    "# Our implementation is 2 lines\n",
    "# YOUR CODE STARTS\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2),tokenizer=LemmaTokenizer(),max_features=50000) \n",
    "values = vectorizer.fit(text_dataset['train']['text'])\n",
    "# YOUR CODE ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1.2:\n",
    "# 1. convert your texts to tf-idf vectors using .transform (training texts and test texts too)\n",
    "# 2. convert your labels into numpy arrays (both training and test labels)\n",
    "# Or implementatin is 4 lines\n",
    "\n",
    "# YOUR CODE STARTS\n",
    "X_train = vectorizer.transform(text_dataset['train']['text'])\n",
    "y_train = np.array(text_dataset['train']['label'])\n",
    "\n",
    "X_test = vectorizer.transform(text_dataset['test']['text'])\n",
    "y_test = np.array(text_dataset['test']['label'])\n",
    "# YOUR CODE ENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "# create LinearSVM model object and fit the model\n",
    "\n",
    "model = svm.LinearSVC() \n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "# note that we can use vector operations, because we deal with numpy tensors\n",
    "accuracy = (predictions == y_test).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько улучшили результат, причем в бОльшей степени за счет использования n-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vectorizers",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
